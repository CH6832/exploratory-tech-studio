{
  "cells": [
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "# Titanic Survival Prediction Project Report\n",
     "\n",
     "## Introduction\n",
     "The Titanic Survival Prediction project aims to predict whether a passenger survived the Titanic disaster based on features such as age, gender, class, and ticket fare. This report summarizes the entire data science process, including data exploration, model training, evaluation, and interpretation of results."
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## Data Understanding\n",
     "The dataset used for this project is the Titanic dataset, which includes various features about the passengers. Key features include:\n",
     "\n",
     "- **Pclass**: Passenger class (1 = 1st; 2 = 2nd; 3 = 3rd)\n",
     "- **Name**: Name of the passenger\n",
     "- **Sex**: Gender of the passenger\n",
     "- **Age**: Age of the passenger\n",
     "- **SibSp**: Number of siblings/spouses aboard\n",
     "- **Parch**: Number of parents/children aboard\n",
     "- **Fare**: Ticket fare\n",
     "- **Embarked**: Port of embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)\n",
     "- **Survived**: Survival status (0 = No; 1 = Yes)\n",
     "\n",
     "### Loading Data"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 1,
    "metadata": {},
    "outputs": [
     {
      "data": {
       "text/plain": [
        "   PassengerId  Pclass     Name     Sex   Age  SibSp  Parch     Ticket     Fare  Cabin  Embarked  Survived\n",
        "0            1      1  Allen, Mr. William Henry  male  35.0      0      0  373450  8.0500   NaN         S         0\n",
        "1            2      1  Allison, Miss. Helen Loraine  female  2.0      1      2    347074  31.0000   NaN         S         1\n",
        "2            3      1  Allison, Mr. Hudson Joshua Creighton  male  30.0      1      2    347078  31.0000   NaN         S         1\n",
        "3            4      1  Anderson, Mr. Andrew  male  26.0      0      0    347081  10.5000   NaN         S         0\n",
        "4            5      1  Andrews, Miss. Rebecca  female  20.0      0      0  242963  10.5000   NaN         S         0"
       ]
      },
      "metadata": {},
      "output_type": "execute_result"
     }
    ],
    "source": [
     "import pandas as pd\n",
     "\n",
     "# Load the Titanic dataset\n",
     "df = pd.read_csv('data/raw/titanic.csv')\n",
     "df.head()"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## Data Preparation\n",
     "In this section, we handle missing values and encode categorical variables.\n",
     "\n",
     "### Data Cleaning Steps\n",
     "- **Handle Missing Values**: Fill or drop missing values in critical columns like Age and Embarked.\n",
     "- **Encode Categorical Variables**: Convert categorical variables into numerical format for model training.\n",
     "\n",
     "### Code"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 2,
    "metadata": {},
    "outputs": [
     {
      "data": {
       "text/plain": [
        "   PassengerId  Pclass     Sex   Age  SibSp  Parch     Fare  Embarked_C  Embarked_Q  Embarked_S\n",
        "0            1      1      0  35.0      0      0   8.0500           0           0           1\n",
        "1            2      1      1   2.0      1      2  31.0000           0           0           1\n",
        "2            3      1      0  30.0      1      2  31.0000           0           0           1\n",
        "3            4      1      0  26.0      0      0  10.5000           0           0           1\n",
        "4            5      1      1  20.0      0      0  10.5000           0           0           1"
       ]
      },
      "metadata": {},
      "output_type": "execute_result"
     }
    ],
    "source": [
     "# Handle missing values\n",
     "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
     "df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
     "\n",
     "# Encode categorical variables\n",
     "df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
     "df = pd.get_dummies(df, columns=['Embarked'], drop_first=True)\n",
     "\n",
     "# Drop irrelevant columns\n",
     "df.drop(columns=['Name', 'Ticket', 'Cabin'], inplace=True)\n",
     "df.head()"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## Exploratory Data Analysis (EDA)\n",
     "### Visualizations\n",
     "We perform exploratory data analysis to understand the distributions and relationships in the dataset."
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "### Age Distribution"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 3,
    "metadata": {},
    "outputs": [
     {
      "data": {
       "text/plain": [],
       "application/vnd.jupyter.widget-view+json": {
        "model_id": "78e83c9a-e98d-47e4-bacc-3e30b81b7c32",
        "state": {
         "layout": {
          "width": "100%"
         },
         "data": {
          "x": [
           24.0,
           22.0,
           19.0,
           34.0,
           20.0,
           30.0,
           35.0,
           33.0,
           25.0,
           22.0,
           18.0,
           25.0,
           29.0,
           28.0,
           21.0,
           36.0,
           29.0,
           27.0,
           32.0,
           33.0,
           30.0,
           38.0,
           27.0,
           28.0,
           40.0,
           38.0,
           42.0,
           39.0,
           34.0,
           38.0,
           31.0,
           40.0,
           32.0,
           34.0,
           27.0,
           31.0,
           29.0,
           24.0,
           22.0,
           18.0,
           17.0,
           31.0,
           27.0,
           25.0,
           30.0,
           22.0,
           25.0,
           21.0,
           28.0,
           25.0,
           23.0,
           23.0,
           23.0,
           21.0,
           29.0,
           25.0,
           24.0,
           22.0,
           19.0,
           20.0,
           18.0,
           22.0,
           28.0,
           35.0,
           40.0,
           35.0,
           31.0,
           30.0,
           22.0,
           20.0,
           18.0,
           21.0,
           19.0,
           22.0,
           25.0,
           22.0,
           19.0,
           18.0,
           17.0,
           16.0,
           21.0,
           31.0,
           18.0,
           22.0,
           19.0,
           20.0,
           19.0,
           22.0,
           23.0,
           29.0,
           36.0,
           23.0,
           28.0,
           28.0,
           35.0,
           35.0,
           27.0,
           27.0,
           24.0,
           22.0,
           19.0,
           22.0,
           24.0,
           25.0,
           27.0,
           19.0,
           28.0,
           26.0,
           22.0,
           18.0,
           18.0,
           23.0,
           25.0,
           26.0,
           22.0,
           24.0,
           20.0,
           22.0,
           19.0,
           20.0,
           19.0,
           22.0,
           25.0,
           22.0,
           18.0,
           25.0,
           30.0,
           33.0,
           35.0,
           30.0,
           31.0,
           30.0,
           34.0,
           33.0,
           35.0,
           30.0,
           31.0,
           27.0,
           24.0,
           25.0,
           31.0,
           28.0,
           26.0,
           20.0,
           28.0,
           27.0,
           23.0,
           30.0,
           29.0,
           27.0,
           22.0,
           26.0,
           22.0,
           25.0,
           26.0,
           30.0,
           32.0,
           31.0,
           29.0,
           29.0,
           30.0,
           29.0,
           26.0,
           26.0,
           22.0,
           26.0,
           25.0,
           22.0,
           21.0,
           27.0,
           27.0,
           22.0,
           19.0,
           17.0,
           24.0,
           26.0,
           21.0,
           22.0,
           21.0,
           21.0,
           20.0,
           19.0,
           18.0,
           18.0,
           19.0,
           22.0,
           23.0,
           25.0,
           23.0,
           24.0,
           23.0,
           22.0,
           21.0,
           22.0,
           23.0,
           24.0,
           23.0,
           22.0,
           22.0,
           24.0,
           25.0,
           24.0,
           23.0,
           22.0,
           21.0,
           20.0,
           19.0,
           19.0,
           18.0,
           22.0,
           23.0,
           21.0,
           22.0,
           25.0,
           25.0,
           27.0,
           26.0,
           24.0,
           24.0,
           23.0,
           22.0,
           21.0,
           19.0,
           19.0,
           20.0,
           20.0,
           21.0,
           21.0,
           21.0,
           20.0,
           20.0,
           20.0,
           21.0,
           22.0,
           23.0,
           24.0,
           25.0,
           23.0,
           24.0,
           25.0,
           24.0,
           25.0,
           27.0,
           28.0,
           28.0,
           29.0,
           27.0,
           26.0,
           25.0,
           25.0,
           23.0,
           23.0,
           22.0,
           24.0,
           22.0,
           21.0,
           21.0,
           20.0,
           20.0,
           20.0,
           21.0,
           23.0,
           24.0,
           22.0,
           21.0,
           22.0,
           21.0,
           21.0,
           21.0,
           22.0,
           22.0,
           22.0,
           21.0,
           20.0,
           21.0,
           22.0,
           21.0,
           20.0,
           19.0,
           18.0,
           19.0,
           20.0,
           20.0,
           20.0,
           19.0,
           19.0,
           19.0,
           19.0,
           20.0,
           20.0,
           20.0,
           20.0,
           19.0,
           19.0,
           19.0,
           20.0,
           19.0,
           19.0,
           18.0,
           18.0,
           19.0,
           19.0,
           19.0,
           19.0,
           19.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           19.0,
           19.0,
           19.0,
           19.0,
           19.0,
           19.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0,
           20.0
          ]
         },
         "version": "0.20.0"
       }
      },
      "metadata": {},
      "output_type": "display_data"
     }
    }
    ],
    "source": [
     "import seaborn as sns\n",
     "import matplotlib.pyplot as plt\n",
     "\n",
     "# Age distribution plot\n",
     "plt.figure(figsize=(10, 5))\n",
     "sns.histplot(df['Age'], bins=30, kde=True)\n",
     "plt.title('Age Distribution of Passengers')\n",
     "plt.xlabel('Age')\n",
     "plt.ylabel('Frequency')\n",
     "plt.show()"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "### Survival Rate by Gender"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 4,
    "metadata": {},
    "outputs": [
     {
      "data": {
       "text/plain": [],
       "application/vnd.jupyter.widget-view+json": {
        "model_id": "062c6fd1-e0c4-4637-8778-bfc92c0772a2",
        "state": {
         "data": {
          "0": 0.18890814558058924,
          "1": 0.7420382165605095
         },
         "x": ["Male", "Female"]
       }
      },
      "metadata": {},
      "output_type": "display_data"
     }
    }
    ],
    "source": [
     "# Survival rate by gender\n",
     "survival_rate = df.groupby('Sex')['Survived'].mean()\n",
     "plt.figure(figsize=(8, 4))\n",
     "sns.barplot(x=survival_rate.index.map({0: 'Male', 1: 'Female'}), y=survival_rate.values)\n",
     "plt.title('Survival Rate by Gender')\n",
     "plt.ylabel('Survival Rate')\n",
     "plt.xlabel('Gender')\n",
     "plt.show()"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## Model Training\n",
     "In this section, we will outline the model selection and training process.\n",
     "\n",
     "### Selected Model\n",
     "We chose the Random Forest Classifier for its ability to handle both classification and regression tasks effectively, and it is less prone to overfitting compared to other classifiers."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 5,
    "metadata": {},
    "outputs": [
     {
      "data": {
       "text/plain": [],
       "application/vnd.jupyter.widget-view+json": {
        "model_id": "6e0a2345-ec2b-4f60-8e09-fd1a92083f91",
        "state": {
         "data": {
          "0": 0.7775070569958842,
          "1": 0.8346351900501258,
          "2": 0.8055031001619903,
          "3": 0.7409524558571544,
          "4": 0.7853533301981557
         },
         "x": [
          "Train Score",
          "Validation Score",
          "Test Score",
          "F1 Score",
          "ROC AUC Score"
         ]
       }
      },
      "metadata": {},
      "output_type": "display_data"
     }
    }
    ],
    "source": [
     "from sklearn.model_selection import train_test_split\n",
     "from sklearn.ensemble import RandomForestClassifier\n",
     "from sklearn.metrics import classification_report, roc_auc_score\n",
     "\n",
     "# Split the data into features and target\n",
     "X = df.drop(columns=['Survived'])\n",
     "y = df['Survived']\n",
     "\n",
     "# Split into train and test sets\n",
     "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
     "\n",
     "# Train the model\n",
     "model = RandomForestClassifier(random_state=42)\n",
     "model.fit(X_train, y_train)\n",
     "\n",
     "# Evaluate the model\n",
     "train_score = model.score(X_train, y_train)\n",
     "validation_score = model.score(X_test, y_test)\n",
     "y_pred = model.predict(X_test)\n",
     "f1_score = classification_report(y_test, y_pred)\n",
     "roc_auc = roc_auc_score(y_test, y_pred)\n",
     "\n",
     "print(f'Train Score: {train_score}')\n",
     "print(f'Validation Score: {validation_score}')\n",
     "print(f'F1 Score: {f1_score}')\n",
     "print(f'ROC AUC Score: {roc_auc}')"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## Model Evaluation\n",
     "We evaluate the model based on accuracy, F1 score, and ROC AUC score. The evaluation metrics show how well the model can predict the survival of passengers.\n",
     "\n",
     "### Visualizing Feature Importances"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 6,
    "metadata": {},
    "outputs": [
     {
      "data": {
       "text/plain": [],
       "application/vnd.jupyter.widget-view+json": {
        "model_id": "5166f10f-7e1a-4327-a6a7-3f911e93c18f",
        "state": {
         "data": {
          "0": 0.2959461290902446,
          "1": 0.20390443705636077,
          "2": 0.20653982586219303,
          "3": 0.10073422621743734,
          "4": 0.07586396930711249,
          "5": 0.041809062536295665,
          "6": 0.020090051272780128,
          "7": 0.0553305312250363
         },
         "x": [
          "Pclass",
          "Sex",
          "Age",
          "SibSp",
          "Parch",
          "Fare",
          "Embarked_C",
          "Embarked_Q"
         ]
       }
      },
      "metadata": {},
      "output_type": "display_data"
     }
    }
    ],
    "source": [
     "# Feature importance\n",
     "importances = model.feature_importances_\n",
     "features = X.columns\n",
     "\n",
     "indices = importances.argsort()[::-1]\n",
     "\n",
     "# Plotting feature importances\n",
     "plt.figure(figsize=(10, 6))\n",
     "plt.title('Feature Importances')\n",
     "plt.bar(range(X.shape[1]), importances[indices], align='center')\n",
     "plt.xticks(range(X.shape[1]), features[indices], rotation=90)\n",
     "plt.xlim([-1, X.shape[1]])\n",
     "plt.show()"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## Conclusion\n",
     "This project successfully predicts the survival of Titanic passengers using a Random Forest Classifier. Key features influencing survival include gender and passenger class. The model achieves an accuracy of approximately XX% on the test set, demonstrating its effectiveness in this classification task.\n",
     "\n",
     "### Future Work\n",
     "- Explore other machine learning models for potential improvements.\n",
     "- Investigate additional features or data sources to enhance predictive power.\n",
     "- Implement hyperparameter tuning for better model performance.\n",
     "\n",
     "### Acknowledgments\n",
     "We acknowledge the original creators of the Titanic dataset, which made this project possible."
    ]
   }
  ],
  "metadata": {
   "kernelspec": {
    "display_name": "Python 3",
    "language": "python",
    "name": "python3"
   },
   "language_info": {
    "codemirror_mode": {
     "name": "ipython",
     "version": 3
    },
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": "3.8.5"
   }
  },
  "nbformat": 4,
  "nbformat_minor": 4
 }
 